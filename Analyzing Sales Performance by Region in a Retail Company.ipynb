{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08f633ea-8378-44aa-836c-d361cae01306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting dask\n",
      "  Downloading dask-2024.7.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: click>=8.1 in c:\\users\\mubashir khan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dask) (8.1.7)\n",
      "Collecting cloudpickle>=1.5.0 (from dask)\n",
      "  Downloading cloudpickle-3.0.0-py3-none-any.whl.metadata (7.0 kB)\n",
      "Requirement already satisfied: fsspec>=2021.09.0 in c:\\users\\mubashir khan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dask) (2024.2.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\mubashir khan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dask) (23.2)\n",
      "Collecting partd>=1.4.0 (from dask)\n",
      "  Downloading partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: pyyaml>=5.3.1 in c:\\users\\mubashir khan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dask) (6.0.1)\n",
      "Requirement already satisfied: toolz>=0.10.0 in c:\\users\\mubashir khan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from dask) (0.12.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\mubashir khan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from click>=8.1->dask) (0.4.6)\n",
      "Collecting locket (from partd>=1.4.0->dask)\n",
      "  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Downloading dask-2024.7.1-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 0.5/1.2 MB 10.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 1.0/1.2 MB 10.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 8.7 MB/s eta 0:00:00\n",
      "Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
      "Downloading partd-1.4.2-py3-none-any.whl (18 kB)\n",
      "Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n",
      "Installing collected packages: locket, cloudpickle, partd, dask\n",
      "Successfully installed cloudpickle-3.0.0 dask-2024.7.1 locket-1.0.0 partd-1.4.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: Loading egg at c:\\users\\mubashir khan\\appdata\\local\\programs\\python\\python312\\lib\\site-packages\\spylon_kernel-0+unknown-py3.12.egg is deprecated. pip 24.3 will enforce this behaviour change. A possible replacement is to use pip for package installation. Discussion can be found at https://github.com/pypa/pip/issues/12330\n",
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dc86d199-7f1a-404a-9ffd-c19ffe24e642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales DataFrame columns: Index(['product_id', 'store_id', 'date', 'sales', 'revenue', 'stock', 'price',\n",
      "       'promo_type_1', 'promo_bin_1', 'promo_type_2', 'promo_bin_2',\n",
      "       'promo_discount_2', 'promo_discount_type_2'],\n",
      "      dtype='object')\n",
      "Product DataFrame columns: Index(['product_id', 'product_length', 'product_depth', 'product_width',\n",
      "       'cluster_id', 'hierarchy1_id', 'hierarchy2_id', 'hierarchy3_id',\n",
      "       'hierarchy4_id', 'hierarchy5_id'],\n",
      "      dtype='object')\n",
      "Store DataFrame columns: Index(['store_id', 'storetype_id', 'store_size', 'city_id'], dtype='object')\n",
      "  product_id store_id        date  sales  revenue  stock  price promo_type_1  \\\n",
      "0      P0001    S0002  2017-01-02    0.0     0.00    8.0   6.25         PR14   \n",
      "1      P0001    S0012  2017-01-02    1.0     5.30    0.0   6.25         PR14   \n",
      "2      P0001    S0013  2017-01-02    2.0    10.59    0.0   6.25         PR14   \n",
      "3      P0001    S0023  2017-01-02    0.0     0.00    6.0   6.25         PR14   \n",
      "4      P0001    S0025  2017-01-02    0.0     0.00    1.0   6.25         PR14   \n",
      "\n",
      "  promo_bin_1 promo_type_2 promo_bin_2  promo_discount_2 promo_discount_type_2  \n",
      "0         NaN         PR03         NaN               NaN                   NaN  \n",
      "1         NaN         PR03         NaN               NaN                   NaN  \n",
      "2         NaN         PR03         NaN               NaN                   NaN  \n",
      "3         NaN         PR03         NaN               NaN                   NaN  \n",
      "4         NaN         PR03         NaN               NaN                   NaN  \n",
      "  product_id  product_length  product_depth  product_width cluster_id  \\\n",
      "0      P0000             5.0           20.0           12.0        NaN   \n",
      "1      P0001            13.5           22.0           20.0  cluster_5   \n",
      "2      P0002            22.0           40.0           22.0  cluster_0   \n",
      "3      P0004             2.0           13.0            4.0  cluster_3   \n",
      "4      P0005            16.0           30.0           16.0  cluster_9   \n",
      "\n",
      "  hierarchy1_id hierarchy2_id hierarchy3_id hierarchy4_id hierarchy5_id  \n",
      "0           H00         H0004       H000401     H00040105   H0004010534  \n",
      "1           H01         H0105       H010501     H01050100   H0105010006  \n",
      "2           H03         H0315       H031508     H03150800   H0315080028  \n",
      "3           H03         H0314       H031405     H03140500   H0314050003  \n",
      "4           H03         H0312       H031211     H03121109   H0312110917  \n",
      "  store_id storetype_id  store_size city_id\n",
      "0    S0091         ST04          19    C013\n",
      "1    S0012         ST04          28    C005\n",
      "2    S0045         ST04          17    C008\n",
      "3    S0032         ST03          14    C019\n",
      "4    S0027         ST04          24    C022\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19454838 entries, 0 to 19454837\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Dtype  \n",
      "---  ------                 -----  \n",
      " 0   product_id             object \n",
      " 1   store_id               object \n",
      " 2   date                   object \n",
      " 3   sales                  float64\n",
      " 4   revenue                float64\n",
      " 5   stock                  float64\n",
      " 6   price                  float64\n",
      " 7   promo_type_1           object \n",
      " 8   promo_bin_1            object \n",
      " 9   promo_type_2           object \n",
      " 10  promo_bin_2            object \n",
      " 11  promo_discount_2       float64\n",
      " 12  promo_discount_type_2  object \n",
      "dtypes: float64(5), object(8)\n",
      "memory usage: 1.9+ GB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 699 entries, 0 to 698\n",
      "Data columns (total 10 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   product_id      699 non-null    object \n",
      " 1   product_length  681 non-null    float64\n",
      " 2   product_depth   683 non-null    float64\n",
      " 3   product_width   683 non-null    float64\n",
      " 4   cluster_id      649 non-null    object \n",
      " 5   hierarchy1_id   699 non-null    object \n",
      " 6   hierarchy2_id   699 non-null    object \n",
      " 7   hierarchy3_id   699 non-null    object \n",
      " 8   hierarchy4_id   699 non-null    object \n",
      " 9   hierarchy5_id   699 non-null    object \n",
      "dtypes: float64(3), object(7)\n",
      "memory usage: 54.7+ KB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 144 entries, 0 to 143\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   store_id      144 non-null    object\n",
      " 1   storetype_id  144 non-null    object\n",
      " 2   store_size    144 non-null    int64 \n",
      " 3   city_id       144 non-null    object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 4.6+ KB\n",
      "None\n",
      "Sales DataFrame columns missing: {'Product ID', 'Sales Amount', 'Store ID'}\n",
      "Product DataFrame columns missing: {'Product ID'}\n",
      "Store DataFrame columns missing: {'Store ID'}\n",
      "KeyError: 'Product ID'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# File paths\n",
    "sales_file_path = r'C:\\Users\\MUBASHIR KHAN\\Desktop\\jupyter\\DMV\\sales.csv'\n",
    "product_file_path = r'C:\\Users\\MUBASHIR KHAN\\Desktop\\jupyter\\DMV\\product_hierarchy.csv'\n",
    "store_file_path = r'C:\\Users\\MUBASHIR KHAN\\Desktop\\jupyter\\DMV\\store_cities.csv'\n",
    "\n",
    "# Load datasets with proper column types\n",
    "dtype_dict_sales = {'Product ID': 'str', 'Store ID': 'str', 'Sales Amount': 'float64'}\n",
    "dtype_dict_product = {'Product ID': 'str'}\n",
    "dtype_dict_store = {'Store ID': 'str'}\n",
    "\n",
    "def load_data(file_path, dtype_dict=None):\n",
    "    try:\n",
    "        return pd.read_csv(file_path, dtype=dtype_dict, low_memory=False)\n",
    "    except MemoryError:\n",
    "        print(\"MemoryError: Unable to load the file.\")\n",
    "        return None\n",
    "\n",
    "# Load datasets\n",
    "sales_df = load_data(sales_file_path, dtype_dict_sales)\n",
    "product_df = load_data(product_file_path, dtype_dict_product)\n",
    "store_df = load_data(store_file_path, dtype_dict_store)\n",
    "\n",
    "# Print the first few rows and column names\n",
    "print(\"Sales DataFrame columns:\", sales_df.columns)\n",
    "print(\"Product DataFrame columns:\", product_df.columns)\n",
    "print(\"Store DataFrame columns:\", store_df.columns)\n",
    "\n",
    "# Print the first few rows of each DataFrame\n",
    "print(sales_df.head())\n",
    "print(product_df.head())\n",
    "print(store_df.head())\n",
    "\n",
    "# Print dataset info\n",
    "print(sales_df.info())\n",
    "print(product_df.info())\n",
    "print(store_df.info())\n",
    "\n",
    "# Check if the required columns are present\n",
    "required_columns_sales = {'Product ID', 'Store ID', 'Sales Amount'}\n",
    "required_columns_product = {'Product ID'}\n",
    "required_columns_store = {'Store ID'}\n",
    "\n",
    "print(\"Sales DataFrame columns missing:\", required_columns_sales - set(sales_df.columns))\n",
    "print(\"Product DataFrame columns missing:\", required_columns_product - set(product_df.columns))\n",
    "print(\"Store DataFrame columns missing:\", required_columns_store - set(store_df.columns))\n",
    "\n",
    "# Adjust column names if necessary (example)\n",
    "# sales_df.rename(columns={'Product ID ': 'Product ID'}, inplace=True)  # Adjust if needed\n",
    "\n",
    "# Merge datasets\n",
    "try:\n",
    "    sales_product_df = pd.merge(sales_df, product_df, on='Product ID', how='left')\n",
    "    sales_product_store_df = pd.merge(sales_product_df, store_df, on='Store ID', how='left')\n",
    "\n",
    "    # Check the merged dataset\n",
    "    print(sales_product_store_df.head())\n",
    "    print(sales_product_store_df.info())\n",
    "\n",
    "    # Group by region and calculate total sales amount\n",
    "    sales_by_region = sales_product_store_df.groupby('Region')['Sales Amount'].sum().reset_index()\n",
    "    sales_by_region = sales_by_region.sort_values(by='Sales Amount', ascending=False)\n",
    "\n",
    "    # Bar plot for sales distribution by region\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x='Region', y='Sales Amount', data=sales_by_region, palette='viridis')\n",
    "    plt.title('Total Sales Amount by Region')\n",
    "    plt.xlabel('Region')\n",
    "    plt.ylabel('Total Sales Amount')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "    # Pie chart for sales distribution by region\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.pie(sales_by_region['Sales Amount'], labels=sales_by_region['Region'], autopct='%1.1f%%', colors=sns.color_palette('viridis', len(sales_by_region)))\n",
    "    plt.title('Sales Distribution by Region')\n",
    "    plt.show()\n",
    "\n",
    "    # Identify top-performing regions\n",
    "    top_regions = sales_by_region.head(5)\n",
    "    print(\"Top Performing Regions:\")\n",
    "    print(top_regions)\n",
    "\n",
    "    # Group by region and product category\n",
    "    sales_by_region_category = sales_product_store_df.groupby(['Region', 'Product Category'])['Sales Amount'].sum().reset_index()\n",
    "\n",
    "    # Pivot the data for better visualization\n",
    "    sales_pivot = sales_by_region_category.pivot(index='Region', columns='Product Category', values='Sales Amount').fillna(0)\n",
    "    print(sales_pivot)\n",
    "\n",
    "    # Stacked bar plot\n",
    "    sales_pivot.plot(kind='bar', stacked=True, figsize=(12, 8), colormap='viridis')\n",
    "    plt.title('Sales Amount by Region and Product Category (Stacked)')\n",
    "    plt.xlabel('Region')\n",
    "    plt.ylabel('Total Sales Amount')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Product Category')\n",
    "    plt.show()\n",
    "\n",
    "    # Grouped bar plot\n",
    "    sales_pivot.plot(kind='bar', figsize=(12, 8), colormap='viridis')\n",
    "    plt.title('Sales Amount by Region and Product Category (Grouped)')\n",
    "    plt.xlabel('Region')\n",
    "    plt.ylabel('Total Sales Amount')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.legend(title='Product Category')\n",
    "    plt.show()\n",
    "\n",
    "except KeyError as e:\n",
    "    print(f\"KeyError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a5d651-9392-48a0-aa2a-6730c9083973",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
